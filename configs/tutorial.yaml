run: [train, test]

cutoff_radius: 5.0
chemical_symbols: [C, O, H]
model_type_names: ${chemical_symbols}

data:
  _target_: nequip.data.datamodule.sGDML_CCSD_DataModule
  dataset: aspirin
  data_source_dir: aspirin_data
  transforms:
    - _target_: nequip.data.transforms.NeighborListTransform
      r_max: ${cutoff_radius}
    - _target_: nequip.data.transforms.ChemicalSpeciesToAtomTypeMapper
      chemical_symbols: ${chemical_symbols}
  trainval_test_subset: [40, 10]
  train_val_split: [30, 10]
  seed: 123
  train_dataloader_kwargs:
    batch_size: 1
  val_dataloader_kwargs:
    batch_size: 5
  test_dataloader_kwargs: ${data.val_dataloader_kwargs}
  stats_manager:
    _target_: nequip.data.DataStatisticsManager
    metrics:
      - field:
          _target_: nequip.data.NumNeighbors
        metric: 
          _target_: nequip.data.Mean
        name: num_neighbors_mean
      - field:
          _target_: nequip.data.PerAtomModifier
          field: total_energy
        metric:
          _target_: nequip.data.Mean
        name: per_atom_energy_mean
      - field: forces
        metric:
          _target_: nequip.data.RootMeanSquare
        per_type: true
        name: per_type_forces_rms
      
train:
  training_module: nequip.train.NequIPLightningModule
  trainer:
    _target_: lightning.Trainer
    max_epochs: 5
    check_val_every_n_epoch: 1
    log_every_n_steps: 5
    callbacks:
      - _target_: lightning.pytorch.callbacks.ModelCheckpoint
        dirpath: ${hydra:runtime.output_dir}
        save_last: true
  loss:
    _target_: nequip.train.MetricsManager
    metrics:
      - name: force_MSE
        field: forces
        coeff: 1
        metric:
          _target_: nequip.train.MeanSquaredError
  val_metrics: 
    _target_: nequip.train.MetricsManager
    metrics:
      - name: force_RMSE
        field: forces
        metric:
          _target_: nequip.train.RootMeanSquaredError
  test_metrics: ${train.val_metrics}
  optimizer:
    _target_: torch.optim.Adam

model:
  # -- network --
  model_builders:
   - allegro.model.Allegro
   # the typical model builders from `nequip` can still be used:
   - PerTypeEnergyScaleShift
   - StressForceOutput
   - RescaleEnergyEtc
  
  # bookkeeping
  seed: 123
  type_names: ${model_type_names}
  model_dtype: float32

  # cutoffs
  r_max: ${cutoff_radius}

  # radial basis
  BesselBasis_trainable: true
  PolynomialCutoff_p: 6   
  num_bessels_per_basis: 8

  # symmetry
  l_max: 1
  parity: o3_full   
  
  # Allegro layers:
  num_layers: 1
  num_tensor_features: 8
  
  two_body_latent_mlp_latent_dimensions: [32, 64, 128]
  two_body_latent_mlp_nonlinearity: silu
  two_body_latent_mlp_initialization: uniform
  
  latent_mlp_latent_dimensions: [128, 128]
  latent_mlp_nonlinearity: silu
  latent_mlp_initialization: uniform
  latent_resnet: true
  
  env_embed_mlp_latent_dimensions: []
  env_embed_mlp_nonlinearity: null
  env_embed_mlp_initialization: uniform
  
  # - end allegro layers -
  
  # Final MLP to go from Allegro latent space to edge energies:
  edge_eng_mlp_latent_dimensions: [32]
  edge_eng_mlp_nonlinearity: null
  edge_eng_mlp_initialization: uniform
  
  # variables derived from dataset statistics
  per_type_energy_scale_shift_shifts: ${training_data_stats:per_atom_energy_mean}
  per_type_energy_scale_shift_scales: ${training_data_stats:per_type_forces_rms} #null
  global_rescale_scale: null #${training_data_stats:forces_rms}
  avg_num_neighbors: ${training_data_stats:num_neighbors_mean}
  
# global options
global_options:
  seed: 789
  allow_tf32: false
